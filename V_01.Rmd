---
title: "Sample_Code"
author: "Caroline X Gao"
date: "29/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
# Install dev_package(s)
# Load dev_package(s)
library(depmixS4) # Must be in depends of pkg
library(ready4use)
```

```{r}
sessionInfo()
```

## Import data

```{r}
dta <- ready4use::Ready4useRepos(dv_nm_1L_chr = "fakes",
                               dv_ds_nm_1L_chr = "https://doi.org/10.7910/DVN/W95KED",
                               dv_server_1L_chr = "dataverse.harvard.edu") %>%
  ingest(fls_to_ingest_chr = "ymh_clinical_dyad_r4") %>%
  procureSlot("b_Ready4useIngest") %>%
  procure("ymh_clinical_dyad_r4") %>%
  procureSlot(slot_nm_1L_chr = "ds_tb") %>% 
    dplyr::rename_with(~stringr::str_replace(.,"aqol6d_q","Q"), .cols = everything()) %>%
  dplyr::rename(ID = fkClientID) %>%
  dplyr::filter(round == "Baseline")
```


```{r}
# Function that fit LCA for n clusters
fit_mix<-function(data,n){
     model_def <- depmixS4::mix(list(Q1 ~ 1, Q2 ~ 1, Q3 ~ 1, Q4~1, Q5~1,
                                Q6 ~ 1, Q7 ~ 1, Q8 ~ 1, Q9~1, Q10~1,
                                Q11 ~ 1, Q12 ~ 1, Q13 ~ 1, Q14~1, Q15~1,
                                Q16 ~ 1, Q17 ~ 1, Q18 ~ 1, Q19~1, Q20~1),
                           family = rep(list(depmixS4::multinomial("identity")), 20),
                           data = data,
                           nstates = n, 
                           nstart=rep(1/n,n))
     fit(model_def)
}

# Function that return fitting index and results for a data set for 2-15clusters
fit_mix_clusters <- function(data){
  
    #define return data structure
    return <- data.frame(
        Classes =integer(),
        AIC=double(),
        BIC=double(), 
        logLik=double(),
        Par=double())
    return_data<-data %>% dplyr::select(ID)
    #loop through all n number of clusters 
    for(n in 2:15){
      
        fit.mod <- fit_mix(data,n)
        return<-rbind(return,data.frame(Classes=n,AIC=AIC(fit.mod),
                                        BIC=BIC(fit.mod),logLik=logLik(fit.mod),Par=fit.mod@npars))
        return_data[[paste0("n",n)]]<-apply(fit.mod@posterior %>% dplyr::select(-state),1,which.max)
    }
    list(return,return_data)
}

# 10 fold CV
CrossValidate <- function(data,
                          folds,
                          n_cores_1L_int = 1L){## Windows, must be one
    # fun training and testing datasets using parallel computing
    final_return <- parallel::mclapply(1:max(folds), function(i) {
        #printing fold 
        print(i)
        # Create training set for this iteration
        training_set <- data[folds != i,]
        #run on training data
        train_return<-fit_mix_clusters(training_set) 
    }, mc.cores = n_cores_1L_int) # Change from 8
    return(final_return)
}
# function extract legend of figure 
g_legend <- function(a.gplot){
  tmp <- ggplot2::ggplot_gtable(ggplot2::ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
  }

# function plot sum domain scores
plot_cluster<- function(data,cluster){
    #extract column name 
    colNames <- names(data)[21:26]
    data$cluster<-cluster
    
    plot<-list()
    # loop summary measures 
    for(i in colNames){ 
    
      labelx<-eval(parse(text=paste0("attributes(dta$",i,")$label")))
      labelx<- str_to_sentence(str_sub(labelx,38,55))
      plot[[i]]<- ggplot(data, aes_string(i)) +
          geom_density(aes(fill=cluster,colour=cluster), alpha=0.4 ,adjust=2.5) +
          labs(x=labelx,y="Density")  + 
          theme_bw() +theme(legend.position="none")+
          scale_fill_manual(values  = c("#fdcc8a","#fc8d59","#e34a33", "#b30000")) +
          scale_colour_manual(values  = c("#fdcc8a","#fc8d59","#e34a33", "#b30000")) 
          
    }          
    #save legend from one plot 
   legend<-ggplot(data, aes_string(i)) +
          geom_density(aes(fill=cluster,colour=cluster), alpha=0.4 ,adjust=2.5) +
          labs(x=labelx,y="Density",fill="Class",col="Class")  + 
          theme_bw() +theme(legend.position="bottom")+
          scale_fill_manual(values  = c("#fdcc8a","#fc8d59","#e34a33", "#b30000")) +
          scale_colour_manual(values  = c("#fdcc8a","#fc8d59","#e34a33", "#b30000")) 
   legend <- g_legend(legend)
   #arrange all plot together
   print(grid.arrange(ggarrange(plotlist=plot,nrow=3,ncol=2) ,
             legend, nrow=2,heights=c(10, 1)))
}
```
```{r}
set.seed(12345)
```

```{r}
folds<- caret::createFolds(dta$Q1, k = 10,list = FALSE)
```

```{r}
results_ls <- readRDS("CV_results.rds")
if(!is.null(results_ls)){
    results<-CrossValidate(dta,folds) # CHANGE TO RESULTS_LS
    saveRDS(results,  "CV_results.rds") # CHANGE TO RESULTS_LS
}
```

```{r}
cv_results <- lapply(results, `[[`, 1)
cv_results <- data.table::rbindlist(cv_results, idcol="Fold") 
```
```{r}

```
## Plot average fitting index

```{r}
plot_average_fit_idx <- function(cv_results,
                                 clss_var_nm_1L_chr = "Classes"){
  nbr_of_clss_1L_dbl <- cv_results$Classes %>% # Generalise
    unique() %>% 
    length() + 1
  plot <- list()
plot_dta1 <- cv_results %>% # RENAME
  dplyr::group_by(Classes) %>% 
  dplyr::summarise(AIC=mean(AIC)) %>% #DIFF
  dplyr::ungroup() 
min1 <- data.frame(Classes = plot_dta1[which.min(plot_dta1$AIC),"Classes"], #DIFF
                   AIC = min(plot_dta1$AIC)) #DIFF
plot[[1]] <- ggplot2::ggplot(plot_dta1) +
  ggplot2::geom_line(ggplot2::aes(x = Classes,
                                  y = AIC)) + #DIFF
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = "none") +
  ggplot2::scale_x_continuous(breaks=2:nbr_of_clss_1L_dbl,
                              limits = c(2, nbr_of_clss_1L_dbl)) +
  ggplot2::geom_point(ggplot2::aes(x =min1$Classes, 
                                   y= min1$AIC), #DIFF
                      color = "red", 
                      size = 3) 
plot_dta2 <- cv_results %>% 
  dplyr::group_by(Classes) %>% 
  dplyr::summarise(BIC=mean(BIC)) %>% #DIFF
  dplyr::ungroup() 
min2 <- data.frame(Classes = plot_dta2[which.min(plot_dta2$BIC),#DIFF
                                       "Classes"],
                   BIC = min(plot_dta2$BIC)) #DIFF
plot[[2]] <- ggplot2::ggplot(plot_dta2) +
  ggplot2::geom_line(ggplot2::aes(x = Classes,
                                  y = BIC) ) + # DIFF
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = "none") +
  ggplot2::scale_x_continuous(breaks = 2:nbr_of_clss_1L_dbl,
                              limits = c(2, nbr_of_clss_1L_dbl))+
  ggplot2::geom_point(ggplot2::aes(x = min2$Classes, 
                                   y = min2$BIC), # DIFF
                      color = "red",
                      size=3) 
plot_dta3 <- cv_results %>% 
  dplyr::group_by(Classes) %>% 
  dplyr::summarise(logLik = mean(logLik)) %>% #DIFF
  dplyr::ungroup() 
max <- data.frame(Classes=plot_dta3[which.max(plot_dta3$logLik),"Classes"],#DIFF #DIFF
                  logLik = max(plot_dta3$logLik)) #DIFF #DIFF
plot[[3]]<-ggplot2::ggplot(plot_dta3) +
  ggplot2::geom_line(ggplot2::aes(x = Classes,
                                  y = logLik) ) + #DIFF
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position="none") + 
  ggplot2::labs(y="Log-likelihood") + #DIFF [EXTRA]
  ggplot2::scale_x_continuous(breaks=2:nbr_of_clss_1L_dbl,
                              limits = c(2, nbr_of_clss_1L_dbl)) +
  ggplot2::geom_point(ggplot2::aes(x = max$Classes, #DIFF
                                   y = max$logLik), #DIFF
                      color = "red",
                      size=3) 
gridExtra::grid.arrange(ggpubr::ggarrange(plotlist = plot, 
                                          ncol=1))
}

```

## Plot individual fitting index
```{r}
plot<-list()
cv_results<-cv_results %>% 
   dplyr::group_by(Fold) %>% 
   dplyr::mutate(minAIC=min(AIC),
          minBIC=min(BIC),
          maxlogLik=max(logLik)) %>% 
   dplyr::mutate(minAIC_which=ifelse(minAIC==AIC,Classes,NA),
          minBIC_which=ifelse(minBIC==BIC,Classes,NA),
          maxlogLikwhich=ifelse(maxlogLik==logLik,Classes,NA)) %>% 
   dplyr::mutate(minAIC_which=max(minAIC_which,na.rm = TRUE),
          minBIC_which=max(minBIC_which,na.rm = TRUE),
          maxlogLikwhich=max(maxlogLikwhich,na.rm = TRUE)) %>% 
   dplyr::ungroup()
plot[[1]] <- ggplot2::ggplot(cv_results, 
                  ggplot2::aes(x = Classes, 
                               y = AIC, # DIFF
                               color=factor(Fold)))  +
  ggplot2::geom_line()  + 
  ggplot2::theme_bw()+
  ggplot2::theme(legend.position="none") +
  ggplot2::scale_x_continuous(breaks = 2:nbr_of_clss_1L_dbl, limits = c(2, nbr_of_clss_1L_dbl)) +
  ggplot2::geom_point(ggplot2::aes(x = minAIC_which,# DIFF
                                   y = minAIC), # DIFF
                      size = 2) 
plot[[2]] <- ggplot2::ggplot(cv_results, 
                  ggplot2::aes(x = Classes, 
                               y = BIC, # DIFF
                               color = factor(Fold))) +
  ggplot2::geom_line()  + 
  ggplot2::theme_bw()+
  ggplot2::theme(legend.position="none") +
  ggplot2::scale_x_continuous(breaks = 2:nbr_of_clss_1L_dbl, limits = c(2, nbr_of_clss_1L_dbl)) +
  ggplot2::geom_point(ggplot2::aes(x = minBIC_which, # DIFF
                                   y = minBIC), # DIFF
                      size = 2) 
plot[[3]] <- ggplot2::ggplot(cv_results, 
                             ggplot2::aes(x = Classes, 
                                          y = logLik, # DIFF 
                                          color = factor(Fold))) + 
  ggplot2::labs(y="Log-likelihood") + # DIFF EXTRA
  ggplot2::geom_line() + 
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position="none") +
  ggplot2::scale_x_continuous(breaks = 2:nbr_of_clss_1L_dbl,
                              limits = c(2, nbr_of_clss_1L_dbl))+
  ggplot2::geom_point(ggplot2::aes(x =maxlogLikwhich, # DIFF 
                                   y=maxlogLik), # DIFF 
                      size=2) 

#save legend from one plot 
legend <- ggplot2::ggplot(cv_results, # USE TTU MTHD
                ggplot2::aes(x = Classes, 
                    y= AIC, 
                    color=factor(Fold))) +
  ggplot2::geom_line() + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position="bottom") +
  ggplot2::labs(col="Datasets")
legend <- g_legend(legend)
gridExtra::grid.arrange(ggpubr::ggarrange(plotlist = plot,
                                  ncol=1),
                        legend, 
                        nrow=2, 
                        heights=c(10, 1))
```
## Agreements between folds
Use Rand index to calculate agreement between each fold.
```{r}
cv_results<-lapply(results, `[[`, 2)
cv_results<-lapply(cv_results, `[`, c(1,4))
cv_dta<- dta %>% 
  dplyr::select(ID)
for(i in 1:10){
  cv_dta <- cv_dta %>% 
    dplyr::left_join(cv_results[[i]])
  names(cv_dta)[i+1]<-paste("fold",i)
}
```
```{r}
cv_dta <- cv_dta %>% dplyr::select(-ID) %>% dplyr::mutate_all(as.factor)
```
```{r}
# function calculate pairwise Rand index between each fold
cal_RI_ij <- function(i,j,data){
  return<-1
  if(i!=j){
  data<-data[,c(i,j)] %>% na.omit()
  return <- aricode::RI(data %>% dplyr::pull(1), # EDITED
                       data %>% dplyr::pull(2)) # EDITED
  }
  return
}
cal_RI <- Vectorize(cal_RI_ij, 
                    vectorize.args = list("i","j"))
```

```{r}
RI <- outer(1:10,1:10,
            cal_RI,
            data = cv_dta)
RI
```
```{r}
#mean RI 
diag(RI) <- NA
mean(RI,na.rm = TRUE)
```
## LOSO CV
Find the best number of classes.

```{r}
folds <- as.factor(dta$s_centre) %>% # EDITED
  as.numeric() # GENERALISE VARIABLE SELECTION
results_ls <- readRDS("LOSO_CV_results.rds") # MAKE THIS A FUNCTION.
if(is.null(results_ls)){
  results <- CrossValidate(dta,folds) 
saveRDS(results,  "LOSO_CV_results.rds")
}
```

```{r}

```

